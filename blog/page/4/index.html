
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>OSv Blog</title>
  <meta name="author" content="Cloudius Systems">

  
  <meta name="description" content="By Tzach Livyatan
This post is a response to the excellent presentation &ldquo;Java Application Servers Are Dead!&rdquo; by Eberhard Wolff.
Go read &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://osv.io/blog/blog/page/4">
  <link href="/blog/favicon.ico" rel="icon">
  <link href="/blog/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/blog/atom.xml" rel="alternate" title="OSv Blog" type="application/atom+xml">
  <script src="/blog/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/blog/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,600,700' rel='stylesheet' type='text/css'>
<!--script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="http://osv.io/js/cycle.js"></script>
<script src="http://osv.io/js/js.js" language="javascript"></script-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43975320-1', 'osv.io');
  ga('send', 'pageview');
</script>

  

</head>

<body   >
  <div class="wrap">
  <div class="header"> <a class="logo" href="http://osv.io"><img src="http://osv.io/images/logo.jpg" /> </a>
    <div class="topMenu">
        <ul class="nav menu">
            <li><a href="http://osv.io">Home</a></li>
            <li class=""><a href="/blog/">Blog</a></li>
            <li class=""><a href="/blog/blog/archives">Archives</a></li>
        </ul>
        <ul class="subscription" data-subscription="rss">
            <li><a href="/blog/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
            
        </ul>
        
        <form action="https://www.google.com/search" method="get">
            <fieldset role="search">
                <input type="hidden" name="q" value="site:osv.io/blog" />
                <input class="search" type="text" name="q" results="0" placeholder="Search"/>
            </fieldset>
        </form>
        
    </div>
</div>
<div class="mobile header">
    <a class="logo" href="http://osv.io/">
        <img src="http://osv.io/images/mobileLogo.jpg"/>
    </a>

    <div class="mobile-topMenu">
        <a href="javascript:void(0)" class="mobileMenuLink">&nbsp;</a>
        <div class="theMobileMenu">
            <ul class="nav menu">
                <li class=""><a href="" >Home</a></li>
                <li class="deeper parent"><a href="/users" >Users</a>
                    <ul class="nav-child unstyled small">
                        
                    </ul>
                </li>
                <li class="deeper parent"><a href="/dev" >Development</a>
                    <ul class="nav-child unstyled small">
                        
                    </ul>
                </li>
                <li class="deeper parent"><a href="/community" >Community</a>
                    <ul class="nav-child unstyled small">
                        
                    </ul>
                </li>
                <li><a href="/contact/" >Contact</a></li>
            </ul>
        </div>
        <script>
            jQuery(document).ready(function(e) {
                $('.mobileMenuLink').click(function(e) {
                    $(this).toggleClass('active');
                    $('.theMobileMenu').slideToggle();
                });
            });
        </script>
    </div>
</div>
<div class="mobile mobilePageTitle"></div>


  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/21/generic-os-is-dead/">If Java Application Servers Are Dead, So Is the Operating System (in the Cloud)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-21T00:00:00-07:00" pubdate data-updated="true">Jul 21<span>st</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Tzach Livyatan</strong>
This post is a response to the excellent presentation <a href="http://www.slideshare.net/ewolff/java-application-servers-are-dead"><strong>&ldquo;Java Application Servers Are Dead!&rdquo;</strong></a> by <a href="https://twitter.com/ewolff">Eberhard Wolff</a>.
Go read his slides and come back here.</p>

<p>Back already?
Assuming you agree with Eberhard’s  claims,  let me demonstrate how
most of his points on Java Application Servers can be applied to a
generic OS (one designed for hardware servers) in the cloud as well.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/blog/2014/07/21/generic-os-is-dead/">Read more&#8230;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/14/osv-shrinker-api/">Getting Started With the OSv Shrinker API</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-14T08:37:05-07:00" pubdate data-updated="true">Jul 14<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Don Marti</strong></p>

<p>If you&rsquo;re writing a program that keeps a cache in memory, you&rsquo;re probably expecting users to have to set the cache size, which means a configuration setting or command-line argument.  And every configuration setting or command-line argument is something that you have to document, or explain to users when they get it wrong.</p>

<p>Thankfully, there&rsquo;s an easier way.</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/blog/2014/07/14/osv-shrinker-api/">Read more&#8230;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/11/osv-boot/">Inside the OSv Boot Process</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-11T08:37:05-07:00" pubdate data-updated="true">Jul 11<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>What happens in that critical fraction of a second between when a virtual x86_64 system &ldquo;powers up&rdquo; and when it begins running operating system code written in a high-level language?</p>

<p>For a helpful walk-through, there&rsquo;s a new article on the OSv wiki, originally written by Elazar Leibovich.</p>

<p><img src="/blog/images/pc-power.jpeg" alt="IBM PC power switch" /></p>

<p><strong>The boot process for a modern VM traces its history back to the
original IBM PC.</strong></p>

<p>While some of the intricate startup steps are historic, the end result is an OSv boot time that&rsquo;s less than a second&mdash;an order of magnitude faster than a conventional multi-user OS.  To read (or contribute!) details,
<a href="http://github.com/cloudius-systems/osv/wiki/OSv-early-boot-(MBR)">the &ldquo;OSv early boot&rdquo; article on the wiki.</a></p>

<p>(photo: <a href="http://commons.wikimedia.org/wiki/File:XT-PC-Power-Supply-PCB-IMG_0436.JPG">Hans Haase for Wikimedia Commons</a>. Available under the Creative Commons Attribution-Share Alike 3.0 Unported license.)</p>

<p>If you have any questions on OSv internals, or porting your application, please join the <a href="https://groups.google.com/forum/#!forum/osv-dev">osv-dev mailing list</a>.  You can get general updates by subscribing to this blog&rsquo;s feed, or folllowing <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems</a> on Twitter.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/07/01/s3stat/">What Is the Most Popular OSv Virtual Appliance?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-01T00:00:00-07:00" pubdate data-updated="true">Jul 1<span>st</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Tzach Livyatan</strong></p>

<p>(Spoiler: It&rsquo;s Apache Tomcat.)</p>

<p><a href="https://github.com/cloudius-systems/capstan">Capstan</a> is a tool for rapidly building and running applications on OSv.
As with Docker, Capstan users can download and run images from a public repository.
We chose to implement our public Capstan repository using <a href="http://aws.amazon.com/s3/">Amazon S3</a>.</p>

<p>Amazon S3  gives us the flexibility and security we need, but by default it&rsquo;s missing a critical feature: download statistics.
This statistics are very interesting to us, to evaluate which of the Capstan virtual appliances are more popular.  Fortunately, there is an easy way to gather the stats we need.</p>

<p>After a short tools survey, we choose <a href="http://www.s3stat.com/">s3stat</a>.</p>

<p><a href="http://www.s3stat.com/">s3stat</a> is a cloud-based service which can follow an S3 bucket, and visualize download statistics, by file, country, browser day, or otherwise.
The price makes sense, and it is super easy to enable.</p>

<p><img src="/blog/images/s3stat_chart.png" alt="s3stat chart" /></p>

<p>So what are the results? (drum roll&hellip;.)</p>

</div>
  
  
    <footer>
      <a rel="full-article" href="/blog/blog/2014/07/01/s3stat/">Read more&#8230;</a>
    </footer>
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/06/23/containers-hypervisors-part-3/">Hypervisors Are Dead, Long Live the Hypervisor (Part 3)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-23T13:00:00-07:00" pubdate data-updated="true">Jun 23<span>rd</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Dor Laor and Avi Kivity</strong></p>

<h1>The new school: functionality, isolation and simplicity</h1>

<p>(This is part 3 of a 3-part series. <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-1/">Part 1</a>, <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-2/">Part 2</a>)</p>

<p>Containers make administration simple, and VMs give you portability, isolation, and administration advantages. The concept of putting <a href="http://www.slideshare.net/jpetazzo/linux-containers-lxc-docker-and-security">containers inside VMs</a> gives you the isolation you need, but there are now two layers of configuration and overhead instead of one.</p>

<p>What if there were one technology that could give us the simplicity and reduced overhead of containers and the security, tools, and hardware support of hypervisors? That’s where OSv comes in.  OSv, the “Operating System Designed for the Cloud.” takes an approach different from either containerization or virtualizing an existing bare-metal OS.  OSv is a single address space OS, designed to run as a guest only, with one application per VM.</p>

<h2>Best of both worlds?</h2>

<p>Glauber Costa, in a speech at Linuxcon called <a href="https://events.linuxfoundation.org/images/stories/pdf/lceu2012_costa.odp">&ldquo;The failure of Operating Systems, and how we can fix it&rdquo;</a>, pointed out that the existence of hypervisors is evidence that Operating Systems alone cannot meet some of the demands of real workloads. Through OSv, we have the opportunity to work together with the hypervisor to create a superior solution to what can be done with the OS alone: combining the resource efficiency of containers with the processor-aided advantages of hardware virtualization.</p>

<p>In the eight years since the release of Intel VMX, the silicon has kept getting better and better at moving the costs of virtualization into hardware. Enterprise customers have been demanding lower virtualization overhead for as long as hypervisors have been a thing, and the best minds of the CPU industry are working on it. With nested page tables and other features coming “for free” on the processor, virtualization overhead is being squeezed closer and closer to parity with bare metal.</p>

<p><img src="/blog/images/duplication.png" alt="typical cloud stack with duplication" /></p>

<p><strong>Typical cloud stacks have duplicate functionality at the hypervisor, guest OS, and application levels.</strong></p>

<p>While many players are trying to carve out a simple OS containerization system at the guest OS level, they are ignoring the stable, simple, secure, hardware-supported interface we already have: the hypervisor-guest interface.  There’s nothing that says we have to use this well-tested, industry-standard interface just to run a large, complete OS designed for bare metal. (In fact, research projects such as “Erlang on Xen” and MirageOS have explored using the hypervisor to run something less than a full OS for quite a while.)</p>

<h2>OSv is designed to perform</h2>

<p>OSv transparently loads an application into its kernel space. There is no userspace whatsoever. It removes the need for user to kernel context switches. In addition, the kernel trusts the application, since it relies on the underlying hypervisor for isolation from other applications in other VMs. Thus it opens up a way for the application to use any kernel API – from taking scheduling decisions to zero copy operations on data, and even unlock the brute force of the hardware page tables for the benefit of the application or its framework.</p>

<p>To date (June 2014), OSv provides 4x better performance for Memcache, a 40% gain with Apache Tomcat, and a 20% gain with Cassandra and SPECjbb. These results are based on our alpha versions, and are likely to improve as we complete the optimizations remaining on our roadmap.</p>

<p><img src="/blog/images/workloads.png" alt="OSv example workloads" /></p>

<p><strong>OSv runs many key cloud workloads with low overhead and high performance.</strong></p>

<p>OSv&rsquo;s image is your app and our kernel. Sometimes it means an image size of 10MB! That&rsquo;s a 100-400x better than the traditional OS and resembles a container&rsquo;s footprint. The OSv boot time is under a second, which is also closer to container startup time.</p>

<h2>OSv management: some questions for devops</h2>

<p>How many configuration files does your OS have? <strong>OSv has zero.</strong></p>

<p>How many times have you had to perform string manipulation on UNIX-like config files? <strong>OSv is built for automation and uses a RESTful API instead.</strong></p>

<p>How hard is it to upgrade your OS, and how can you revert it? <strong>OS is stateless.</strong></p>

<p>With an hypervisor below, you get the features such as live migration, perfect SLA, superior security for free while you get to enjoy from OSv’s added value.</p>

<h2>Capstan – or what we have learned from Docker</h2>

<p>We do love Docker with regard to development. The neat public image repository and the dead-simple-single execution won our hearts. We wanted to have the same for VMs, so we created the <a href="http://osv.io/capstan/">Capstan</a> project. Capstan has a public image repository, and by executing &lsquo;capstan run cloudius/osv-cassandra&rsquo; a virtual machine image will be either downloaded to your laptop (Mac OS X, Microsoft Windows, or Linux) or be executed on your cloud of choice. Capstan also allows you to build images including an app and a base OSv image. It takes about three seconds. On Capstan&rsquo;s roadmap, we plan to support the Docker file format, run Java apps directly without a config file, and form a simple PaaS for developers to load their favorite app directly to a running VM.</p>

<h2>Pick a cloud, any cloud</h2>

<p>The business case for cloud computing has never been better for the customer. While Amazon continues to upgrade the available instances and offer faster VMs at lower prices, Google is coming on strong as well. Microsoft, HP, IBM, and others are all competing for cloud business.  The cloud VM is the new generic PC.  Because we can create standard VMs that will run on anyone’s cloud, or on a private or hybrid cloud, we can develop with the confidence that we’ll be able to deploy to whatever infrastructure makes business sense&mdash;or move, or split deployment.</p>

<p>Lastly, we like to point out we are not against containers. Container technology is awesome when used for the right scenario. As there are cases for public transportation versus private cars, the same applies to devops. Both containers and OSv excel, in different domains. Here is a simple flow chart that can guide you with your choices:</p>

<p><a href="/blog/images/flowchart.png"><img src="/blog/images/flowchart.png" alt="Guest OS selection flowchart" /></a></p>

<p>Using OSv on ubiquitous, secure, full-featured hypervisors is the way to keep performance up, costs down, and options open. We had to completely reinvent the guest OS to do it&mdash;but now that we have it, OSv is available to build on. Please join the <a href="https://groups.google.com/forum/#!forum/osv-dev">osv-dev mailing list</a> for technical info, or follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems on Twitter</a> for the latest news.</p>

<p>( <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-1/">Part 1</a>, <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-2/">Part 2</a>
)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/06/19/containers-hypervisors-part-2/">Hypervisors Are Dead, Long Live the Hypervisor (Part 2)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-19T13:00:00-07:00" pubdate data-updated="true">Jun 19<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Dor Laor and Avi Kivity</strong></p>

<h1>Linux containers</h1>

<p>(This is part 2 of a 3-part series. <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-1/">Part 1 was published yesterday.</a>)</p>

<p>Containers, which create isolated compartments at the operating system level instead of adding a separate hypervisor level, trace their history not to mainframe days, but to Unix systems.</p>

<p>FreeBSD introduced “jails” in 2000. There’s a good description of them in  <a href="http://phk.freebsd.dk/pubs/sane2000-jail.pdf">Jails: Confining the omnipotent root by Poul-Henning Kamp and Robert N. M. Watson</a>. Solaris got its Zones in 2005.  Both systems allowed for an isolated “root” user and root filesystem.</p>

<p>The containers we know today, <a href="https://linuxcontainers.org/">Linux Containers</a>, or LXC, are not a single monolithic system, but more of a concept, based on a combination of  several different isolation mechanisms built into Linux at the kernel level.  <a href="https://lwn.net/Articles/587545/">Linux Containers 1.0 was released earlier this year.</a>, but many of the underlying systems have been under development in Linux independently.  Containers are not an all-or-nothing design decision, and it’s possible for different systems to work with them in different ways. <a href="https://linuxcontainers.org/">LXC can use all of the following Linux features</a>:</p>

<ul>
<li><p>Kernel namespaces (ipc, uts, mount, pid, network and user)</p></li>
<li><p>AppArmor and SELinux profiles</p></li>
<li><p>Seccomp policies</p></li>
<li><p>Chroots (using pivot_root)</p></li>
<li><p>Kernel capabilities</p></li>
<li><p>Control groups (cgroups)</p></li>
</ul>


<p>Although the combination can be complex, there are tools that make containers simple to use. For several years userspace tools such as LXC, libvirt allowed users to manage containers. However, containers didn’t really get picked up by the masses until the creation of <a href="https://www.docker.io/">Docker</a>. Docker and <a href="http://man7.org/linux/man-pages/man1/systemd-nspawn.1.html">systemd-nspawn</a> can start containers with minimal configuration, or from the command line. The Docker developers deserve much credit for adding two powerful concepts above the underlying container complexity:
a. Public image repository &ndash; immediate search and download of containers pre-loaded with dependencies, and
b. Dead-simple execution &ndash; a one-liner command for running a container.</p>

<p><img src="/blog/images/docker.png" alt="Docker diagram" /></p>

<p><strong><a href="https://www.docker.io/the_whole_story/">Docker gives container users a simple build process and a public repository system.</a></strong></p>

<h2>Container advantages</h2>

<p>When deployed on a physical machine, containers can eliminate the need of running two operating systems, one on top of the other (as in traditional virtualization). It makes IO system calls almost native and the footprint is minimal. However, this comes with a cost as we will detail below. The rule of the thumb is that if you do not need multi-tenancy and you’re willing to do without a bunch of software defined features, containers on bare metal are perfect for you!</p>

<p>In production, <a href="https://speakerdeck.com/jbeda/containers-at-scale">Google uses containers extensively</a>, starting more than two billion per week. Each container includes an application, built together with its dependencies, and containerization helps the company manage diverse applications across many servers.</p>

<p>Containers are an excellent case for development and test. It becomes possible to test some fairly complex setups, such as a version control system with hooks, or an SMTP server with spam filters,  by running services in a container. Because a container can use namespaces to get a full set of port numbers, it’s easy to run multiple complex tests at a time. The systemd project even uses containers for testing their software, which manages an entire Linux system. Containers are highly useful for testing because of their fast startup time&mdash;you’re just invoking an isolated set of processes on an existing kernel, not booting an entire guest OS.</p>

<p>If you run multiple applications that depend on different versions of a dependency, then deploying each application within its own container can allow you to avoid dependency conflict problems. Containers in theory decouple the application from the operating system. We use the term &lsquo;in theory&rsquo; because lots of care and thought should be given to maintaining your stack. For example, will your container combo be supported by the host OS vendor? Is your container up-to-date and does it include fixes for bugs such as ‘heartbleed’? Is your host fully updated, and does its kernel API provide the capabilities your application requires?</p>

<p>We highly recommend the use of containers whenever your environment is homogeneous:</p>

<ul>
<li><p>No multitenancy</p></li>
<li><p>Application is always written with clustering in mind</p></li>
<li><p>Load balancing is achieved by killing running apps and re-spinning them elsewhere (as opposed to live migration)</p></li>
<li><p>No need to run different kernel versions</p></li>
<li><p>No underlying hypervisor (otherwise, you&rsquo;re just adding a layer)</p></li>
</ul>


<p>When the above apply, you will enjoy near bare-metal performance, a small footprint and fast boot time.</p>

<h2>Container disadvantages: Security</h2>

<p>It’s clear that a public cloud needs strong isolation separating tenant systems. All that an attacker needs is an email address and a credit card number to set up a hostile VM on the same hardware as yours. But strong isolation is also needed in private clouds behind the corporate firewall. Corporate IT won’t be keen to run <strong>sandbox42.interns.engr.example.com</strong> and <strong>payroll.example.com</strong> within the same security domain.</p>

<p>Hypervisors have a relatively simple security model. The interface between the guest and the hypervisor is well defined, based on real or virtual hardware specifications. Five decades of hypervisor development have helped to form a stable and mature interface. Large portions of the interface&rsquo;s security are enforced by the physical hardware.</p>

<p>Containers, on the other hand, are implemented purely in software. All containers and their host share the same kernel. Nearly the entire Linux kernel had to undergo changes in order to implement isolation for resources such as memory management, network stack, I/O, the scheduler, and user namespaces. The Linux community is investing a lot of effort to improve and expand container support. However, rapid development makes it harder to stabilize and harden the container interfaces.</p>

<h2>Container disadvantages: Software-defined data center</h2>

<p>Hypervisors are the basis for the new virtualized data center. They allow us to perfectly abstract the hardware and play nicely with networking and storage.
Today there isn&rsquo;t a switch or a storage system without VM integration or VM-specific features.</p>

<p>Can a virtualized data center be based on containers in place of hypervisors? At almost all companies, no.. There will always be security issues with mounting SAN devices and filesystems from containers in different security domains. Yes, containers are a good fit for plenty of tasks but are restricted when it comes to sensitive areas such as you data center building blocks such as the storage and the network.</p>

<p>No one operating system, even Linux, will run 100% of the applications in the data center. There will always be diversity at the data center, and the existence of different operating systems will force the enterprise to keep the abstraction at the VM level.</p>

<h2>Container disadvantages: Management</h2>

<p>The long history of hypervisors means that the industry has developed a huge collection of tools for real-world administration needs.</p>

<p><img src="/blog/images/esx2.jpg" alt="CPM monitoring in VMware" /></p>

<p><strong><a href="http://robertmorannet.blogspot.com/2010/08/vmware-vsphere-screenshots.html">Blogger Robert Moran shows a screenshot of CPU monitoring in VMware’s vSphere</a>.</strong></p>

<p>The underlying functionality for hypervisor management is also richer. All of the common hypervisors support “live migration” of guests from one host to another.</p>

<p>Hypervisors have become an essential tool in the community of practice around server administration. Corporate IT is in the process of virtualizing its diverse collection of servers, running modern and vintage Linux distributions, plus legacy operating systems, and hypervisor vendors including VMWare and Microsoft are enabling it.</p>

<h2>Container disadvantages: Complexity</h2>

<p>While containers take advantage of the power built into Linux, they share Linux’s complexity and diversity.  For example, each Linux distribution standardizes on a different kernel version, and some use AppArmor while others use SELinux. Because containers are implemented using multiple isolation features at the OS level, the “containerization” features can vary by kernel version and platform.</p>

<h2>The anatomy of a multi-tenant exploit</h2>

<p>Let&rsquo;s assume a cloud vendor, whether SaaS, IaaS, or PaaS, implements a service within a container. How would an attacker exploit it?
The first stage would be to gain control of the application within the container. Many applications have flaws and the attacker would need to exploit an existing unpatched CVE in order to gain access to the container. IaaS even makes it simpler as the attacker already has a “root” shell inside a neighboring container.</p>

<p>The next stage would be to penetrate the kernel. Unfortunately, the kernel&rsquo;s attack surface contains hundreds of system calls, and other vulnerabilities exist in the form of packets and file metadata that can jeopardize the kernel. Many attackers have access to zero-day exploits, unpublished local kernel vulnerabilities. (A typical “workflow” is to watch upstream kernel development for security-sensitive fixes, and figure out how to exploit them on the older kernels in production use.)</p>

<p>Once the hacker gains control of the kernel, it&rsquo;s game over. All the other tenants’ data is exposed.</p>

<p>The list of exploitable bugs is always changing, and there will probably be more available by the time you read this.  A few recent examples:</p>

<ul>
<li><p>“An information leak was discovered in the Linux kernel&rsquo;s SIOCWANDEV ioctl call. A local user with the CAP_NET_ADMIN capability could exploit this flaw to obtain potentially sensitive information from kernel memory.“ (CVE-2014-1444) Some container configurations have CAP_NET_ADMIN, while others don’t. Because it’s possible to set up containers in more or less restricted ways, individual sites need to check if they’re vulnerable. (Many LInux capabilities are <a href="http://forums.grsecurity.net/viewtopic.php?f=7&amp;t=2522">equivalent to root</a> because they can be used to obtain root access.)</p></li>
<li><p>“An information leak was discovered in the wanxl ioctl function in  Linux. A local user could exploit this flaw to obtain potentially sensitive information from kernel memory.” (CVE-2014-1445)”</p></li>
<li><p>“An unprivileged local user with access to a CIFS share could use this flaw to crash the system or leak kernel memory. Privilege escalation cannot be ruled out (since memory corruption is involved), but is unlikely.“ (CVE-2014-0069)</p></li>
</ul>


<p>Each individual vulnerability is usually fixed quickly, but there’s a constant flow of new ones for attackers to use. <a href="https://lwn.net/Articles/462756/">Linux filesystem developer Ted Ts’o wrote</a>,</p>

<blockquote><p>Something which is baked in my world view of containers (which I suspect is not shared by other people who are interested in using containers) is that given that the kernel is shared, trying to use containers to provide better security isolation between mutually suspicious users is hopeless.  That is, it&rsquo;s pretty much impossible to prevent a user from finding one or more zero day local privilege escalation bugs that will allow a user to break root.  And at that point, they will be able to penetrate the kernel, and from there, break security of other processes.</p>

<p>So if you want that kind of security isolation, you shouldn&rsquo;t be using containers in the first place.  You should be using KVM or Xen, and then only after spending a huge amount of effort fuzz testing the KVM/Xen paravirtualization interfaces.</p></blockquote>

<p><a href="http://permalink.gmane.org/gmane.linux.coreos.devel/287">Kernel developer Greg Kroah-Hartman wrote</a>,</p>

<blockquote><p>Containers are not necessarily a &ldquo;security&rdquo; boundary, there are many &ldquo;leaks&rdquo; across it, and you should use it only as a way to logically partition off users/processes in a way that makes it easier to manage and maintain complex systems. The container model is quite powerful and tools like docker and systemd-nspawn provide a way to run multiple &ldquo;images&rdquo; at once in a very nice way.</p></blockquote>

<p>Containers are powerful tools for Linux administrators, but for true multi-tenant cloud installations, we need stricter isolation between tenants.</p>

<p>Containerization is not “free”. For instance, the Linux Memory Controller can slow down the kernel by as much as 15%, just by being enabled, with no users. The Memory Controller itself is complicated, but cgroups controllers, on which it depends, are also complex. The surface of change is just way too big, and the resulting implementation necessarily too complex. <a href="https://plus.google.com/109487070944143253361/posts/6AdwyTfPFQe">George Dunlap said it best</a>,</p>

<blockquote><p>With containers you&rsquo;re starting with everything open and then going around trying to close all the holes; if you miss even a single one, bam, you lose. With VMs, you start with almost everything closed, and selectively open things up; that makes a big difference.</p></blockquote>

<p><strong>This is part 2 of a 3-part series.</strong> Please subscribe to our <a href="/blog/atom.xml">feed</a> or follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems</a> to get a notification when part 3 is available.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/06/19/containers-hypervisors-part-1/">Hypervisors Are Dead, Long Live the Hypervisor (Part 1)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-19T13:00:00-07:00" pubdate data-updated="true">Jun 19<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Dor Laor and Avi Kivity</strong></p>

<p>The hypervisor is the basic building block of cloud computing; hypervisors drive the software-defined data center revolution, and two-thirds of all new servers are virtualized today. Hypervisors for commodity hardware have been the key enabler for the software revolution we have been experiencing.</p>

<p>However, for the past 8 years a parallel technology has been growing, namely, containers. Recently containers have been getting a fairly large amount of traction with the development of the Docker project. When run on bare metal, containers perform better than hypervisors and have a lower footprint.</p>

<p>There is a lot in common with the goals of these technologies. These three blog entries will try to provide an answer to the question</p>

<p><strong>Will containers kill the hypervisor?</strong></p>

<p>The series will provide in-depth explanations about the underlying technology and the pros and cons of each solution.</p>

<h2>Intro: ancient hypervisor lore</h2>

<p>What is virtualization anyway?</p>

<p><img src="/blog/images/virtualization.png" alt="Virtualization diagram" /></p>

<p>A hypervisor is a software component (potentially assisted by hardware) that allows us to run multiple operating systems on the same physical machine. The overlay OS is called the guest OS or simply, a Virtual Machine (VM). The guest OS may not even be aware it is running on virtual hardware.</p>

<p>The interface between the guest and the host is the hardware specification. It covers the CPU itself and any other hardware devices, from BIOS to NICs, SCSI adapters, GPUs and memory.</p>

<p><img src="/blog/images/IBM360-67AtUmichWithMikeAlexander.jpg" alt="IBM System/360" /></p>

<p><strong>IBM, together with MIT and the University of Michigan, pioneered hypervisor technology on System/360 and System/370 mainframes, beginning in the 1960s.</strong></p>

<p>IBM was the first company to produce hypervisors. The IBM System/360, model 1967, was the first to <a href="http://www.beagle-ears.com/lars/engineer/comphist/ibm360.htm#gener">ship with virtual memory hardware supporting virtualization</a>. The next system in the series, System/370, was the “private cloud” of its day. Administrators could set up virtual machines for running different OS versions, and even public-cloud-like “time sharing” by multiple customers.</p>

<h2>Virtualization for x86</h2>

<p>Virtualization didn’t make it to commodity systems until the <a href="http://www.vmware.com/company/news/mediaresource/milestones">release of VMware Workstation in 1999</a>. In the early 2000s, hypervisors were based on pure software and were mostly useful for development and testing.  VMware initially used a technique called dynamic translation to intercept privileged operations by the guest operating system. When the guest accessed “hardware”, VMWare rewrote the instructions on the fly, to protect itself from the guest and isolate guests from each other.</p>

<p><img src="/blog/images/vmware-logo.png" alt="VMware logo" /></p>

<p>Later on, the open source Xen hypervisor project coined the term paravirtualization (PV). PV guests, which have to be specially modified to run on a PV host, do not execute privileged instructions themselves but ask the hypervisor to do it on their behalf.</p>

<p><img src="/blog/images/xen-logo.png" alt="Xen logo" /></p>

<p>Eventually, Intel, AMD and ARM implemented support for virtualization extensions. A special host mode allows running guest code on the bare CPU, getting near 100% of bare metal throughput for CPU-intensive workloads. In parallel, the memory management and the IO path received attention as well with technologies such as nested paging (virtual memory), virtual interrupt controllers, single-root I/O virtualization (SRIOV) and other optimizations.</p>

<h2>Hardware support for hypervisors</h2>

<p>Hypervisor enablement continues to be a priority for hardware manufacturers. <a href="https://plus.google.com/+OsvIo/posts/fgzsepcScTa">Glauber Costa wrote</a>, “the silicon keeps getting better and better at taking complexity away from software and hiding somewhere else.”</p>

<p><a href="http://www.redhat.com/rhecm/rest-rhecm/jcr/repository/collaboration/jcr:system/jcr:versionStorage/5e7884ed7f00000102c317385572f1b1/1/jcr:frozenNode/rh:pdfFile.pdf">According to a paper from Red Hat Software</a>,</p>

<blockquote><p>Both Intel and AMD continue to add new features to hardware to improve performance for virtualization. In so doing, they offload more features from the hypervisor into “the silicon” to provide improved performance and a more robust platform&hellip;.These features allow virtual machines to achieve the same I/O performance as bare metal systems.</p></blockquote>

<h2>Old-school hypervisors</h2>

<p>Hypervisors are one of the main pillars of the IT market (try making your way through downtown San Francisco during VMworld) and solve an important piece of the problem. Today the hypervisor layer is commoditized, users can choose any hypervisor they wish when they deploy Open Stack or similar solutions.</p>

<p>Hypervisors are a mature technology with a rich set of tools and features ranging from live migration, cpu hotplug, software defined networking and other new coined terms that describe the virtualization of the data center.</p>

<p>However, in order to virtualize your workload, one must deploy a full fledged guest operating system onto every VM instance. This new layer is a burden in terms of management and in terms of performance overhead. We’ll look at one of the other approaches to compartmentalization next time: containers.</p>

<p><strong>This is part 1 of a 3-part series.</strong>  <a href="http://osv.io/blog/blog/2014/06/19/containers-hypervisors-part-2/">Part 2 is now available</a>.  Please subscribe to our <a href="/blog/atom.xml">feed</a> or follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems</a> to get a notification of future posts.</p>

<p>Photo credit, IBM 360: <a href="http://commons.wikimedia.org/wiki/File:IBM360-67AtUmichWithMikeAlexander.jpg">Dave Mills for Wikimedia Commons</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/06/18/usenix-atc/">Nadav Har’El Presenting OSv at USENIX June 19th</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-18T08:54:23-07:00" pubdate data-updated="true">Jun 18<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Don Marti</strong></p>

<p>If you&rsquo;re attending the USENIX Annual Technical Conference, be sure not to miss
<a href="https://www.usenix.org/conference/atc14/technical-sessions/presentation/kivity">&ldquo;OSv—Optimizing the Operating System for Virtual Machines&rdquo; </a>. Nadav Har&#8217;El will be presenting tomorrow at 10:40 AM.</p>

<p>Here&rsquo;s a quick preview of some of the performance results that Nadav will show:</p>

<p><img src="/blog/images/usenix-paper.png" alt="table from upcoming paper" /></p>

<p>It&rsquo;s also your opportunity to ask Nadav some hard questions.</p>

<p>If you&rsquo;re not at USENIX this year, you can still get a copy of the paper.</p>

<p>Thanks to the USENIX open access policy, the paper is scheduled to go Open Access on the day of the event. To get an alert from us when it&rsquo;s up, please follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems on Twitter</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/06/06/capstan-push/">Using Capstan With Local OSv Images</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-06-06T08:54:23-07:00" pubdate data-updated="true">Jun 6<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Don Marti</strong></p>

<p>If you&rsquo;re building OSv from source, you can use the <code>capstan push</code> command to temporarily use a local build in place of a base image from a network repository.  This is handy when you&rsquo;re trying your application with a patched version of OSv.   Just run <code>capstan push</code> after the OSv build to push your newly built image into your local Capstan repository.</p>

<p>For example, if your Capstanfile uses the <code>cloudius/osv-base</code> base image:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>make 
</span><span class='line'>capstan push cloudius/osv-base  build/release/usr.img</span></code></pre></td></tr></table></div></figure>


<p>When you&rsquo;re ready to go back to using the image from the network, you can run</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>capstan pull cloudius/osv-base</span></code></pre></td></tr></table></div></figure>


<p>to replace the image in your local repository with the image from the network repository.</p>

<p>For more tips and updates, please follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems on Twitter</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/blog/2014/05/19/usenix-atc/">OSv Paper Coming to USENIX in June</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-05-19T08:54:23-07:00" pubdate data-updated="true">May 19<span>th</span>, 2014</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>By Don Marti</strong></p>

<p>We&rsquo;re going to the USENIX Annual Technical Conference
in Philadelphia!</p>

<p><a href="https://www.usenix.org/conference/fcw14"><img src="https://www.usenix.org/sites/default/files/fcw14_banner_450x93.png" border="0" alt="2014 Federated Conferences Week"></a></p>

<p><a href="https://www.usenix.org/conference/atc14/technical-sessions/presentation/kivity">Our paper, &ldquo;OSv—Optimizing the Operating System for Virtual Machines&rdquo; </a> has been accepted by one of our favorite IT events.  We appreciate all the excellent comments and questions from our peer reviewers.</p>

<p>This year, ATC will be part of a Federated Conferences Week that includes HotCloud, HotStorage, two days of sysadmin training, and more, so there should be something for everyone.</p>

<p>The paper will be available under Open Access terms starting on the date of the event, but we all hope you can come see us live and in person.</p>

<p>Here&rsquo;s the abstract:</p>

<blockquote>
<p>Virtual machines in the cloud typically run existing general-purpose operating systems such as Linux. We notice that the cloud’s hypervisor already provides some features, such as isolation and hardware abstraction, which are duplicated by traditional operating systems, and that this duplication comes at a cost.</p>

<p>We present the design and implementation of OSv, a new guest operating system designed specifically for running a single application on a virtual machine in the cloud. It addresses the duplication issues by using a low-overhead library-OS-like design. It runs existing applications written for Linux, as well as new applications written for OSv . We demonstrate that OSv is able to efficiently run a variety of existing applications. We demonstrate its sub-second boot time, small OS image and how it makes more memory available to the application. For unmodified network-intensive applications, we demonstrate up to 25% increase in throughput and 47% decrease in latency. By using non-POSIX network APIs, we can further improve performance and demonstrate a 290% increase in Memcached throughput.</p>
</blockquote>


<p>For more event updates, please follow <a href="https://twitter.com/CloudiusSystems">@CloudiusSystems on Twitter</a>.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/blog/page/5/">&larr; Older</a>
    
    <a href="/blog/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/blog/page/3/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/blog/2015/03/31/sdi/">Software-defined Interconnection: The Future of Internet Peering, Powered by OpenDaylight and OSv</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2015/02/20/seastar/">Seastar: New C++ Framework for Web-scale Workloads</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2015/02/02/mikelangelo/">Researching the Future of the Cloud</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2015/01/14/performance-evaluation/">Unikernel Research at the University of Utah</a>
      </li>
    
      <li class="post">
        <a href="/blog/blog/2015/01/07/meetup/">OSv Meetup Group in Bangalore, India</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  </div>
  <div class="footer">
    <div class="wrapf">


        <div class="custom"  >
            <p><a href="http://www.cloudius-systems.com"><img style="margin-top: 30px;" src="http://osv.io/images/footerLogo.jpg" alt="" width="380" height="38" /></a></p></div>



        <div class="custom social"  >
            <p><a href="https://plus.google.com/107787008629542080430" rel="publisher">Google+</a></p></div>



        <div class="custom CloudIcon"  >
            <p><a href="/index.php"><img src="http://osv.io/images/footerCloudIcon.jpg" width="57" height="33" alt="footerCloudIcon" /></a></p></div>

        <div class="clr"></div>
    </div>
</div>


  

<script type="text/javascript">
      var disqus_shortname = 'osvblog';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id; js.async = true;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
